import json
from pathlib import Path

import pytest
from requests import Session

from fuzzer.fuzzer import create_scenario, get_infra

from .scenario import Scenario
from .services import EDITOAST_URL

REGRESSION_TESTS_DATA_FOLDER = Path(__file__).parent / "regression_tests_data"
REGRESSION_TESTS_JSON_FILES = [
    str(json_file.relative_to(REGRESSION_TESTS_DATA_FOLDER))
    for json_file in REGRESSION_TESTS_DATA_FOLDER.rglob("*.json")
]


"""
This file runs the regression tests generated by the fuzzer.
"""


def _schedule_with_payload(
    editoast_url: str,
    payload: dict,
    accept_400: bool,
    scenario: Scenario,
    session: Session,
) -> int | None:
    """
    Send a schedule request with the given payload, raises an error if the request failed (unless we accept 400s).
    Returns the schedule id.
    """
    r = session.post(
        editoast_url + f"/timetable/{scenario.timetable}/train_schedules/", json=payload
    )
    if r.status_code // 100 != 2:
        if r.status_code // 100 == 4 and accept_400:
            return None
        raise RuntimeError(f"Schedule error {r.status_code}: {r.content}")
    return r.json()[0]["id"]


def _stdcm_with_payload(
    editoast_url: str, payload: dict, scenario: Scenario, session: Session
):
    """
    Send a stdcm request with the given payload, raises an error if the request failed.
    """
    url = (
        editoast_url + f"/timetable/{scenario.timetable}/stdcm/?infra={scenario.infra}"
    )
    r = session.post(url, json=payload)
    if r.status_code // 100 != 2:
        raise RuntimeError(f"stdcm error {r.status_code}: {r.content}")


def _update_stdcm_payload(payload, rolling_stock_id: int):
    """
    Edit the given stdcm payload to replace the ids for the rolling stock.
    """
    payload["rolling_stock_id"] = rolling_stock_id


def _check_result(editoast_url: str, schedule_id: int, infra_id: int, session: Session):
    """
    Get the /result/ of the given train id. The function doesn't return anything, it just raises any error
    """
    r = session.get(
        f"{EDITOAST_URL}train_schedule/{schedule_id}/simulation/?infra_id={infra_id}"
    )
    if r.status_code // 100 != 2 or r.json().get("status", "") != "success":
        raise RuntimeError(
            f"Schedule error {r.status_code}: {r.content}, id={schedule_id}"
        )


def _apply_prelude(
    prelude: list, editoast_url: str, scenario: Scenario, session: Session
):
    """
    Send the requests from the test prelude to fill the timetable with trains
    """
    for train in prelude:
        assert "schedule_payload" in train

        schedule_payload = train["schedule_payload"]
        schedule_id = _schedule_with_payload(
            editoast_url,
            schedule_payload,
            accept_400=False,
            scenario=scenario,
            session=session,
        )
        assert schedule_id is not None

        _check_result(editoast_url, schedule_id, scenario.infra, session)


def _reproduce_test(
    path_to_json: Path,
    scenario: Scenario,
    rolling_stock_id: int,
    session: Session,
):
    """
    Reproduce one given test using the json generated by the fuzzer for one error case
    """
    fuzzer_output = json.loads(path_to_json.read_bytes())
    is_private_infra = fuzzer_output["infra_name"] not in ["small_infra", "Small Infra"]
    if is_private_infra:
        infra_id = get_infra(EDITOAST_URL, fuzzer_output["infra_name"], session)
        scenario = create_scenario(EDITOAST_URL, infra_id)

    if fuzzer_output["error_type"] == "STDCM":
        _apply_prelude(
            fuzzer_output.get("prelude", []), EDITOAST_URL, scenario, session
        )
        payload = fuzzer_output["stdcm_payload"]
        _update_stdcm_payload(payload, rolling_stock_id)
        _stdcm_with_payload(EDITOAST_URL, payload, scenario, session)
        return

    stop_after_schedule = fuzzer_output["error_type"] == "SCHEDULE"

    payload = fuzzer_output["schedule_payload"]
    schedule_id = _schedule_with_payload(
        EDITOAST_URL, payload, stop_after_schedule, scenario, session
    )
    assert schedule_id is not None
    if stop_after_schedule:
        return

    _check_result(EDITOAST_URL, schedule_id, scenario.infra, session)


@pytest.mark.parametrize("file_name", REGRESSION_TESTS_JSON_FILES)
def test_regressions(
    file_name: str,
    small_scenario: Scenario,
    fast_rolling_stock: int,
    session: Session,
):
    _reproduce_test(
        REGRESSION_TESTS_DATA_FOLDER / file_name,
        small_scenario,
        fast_rolling_stock,
        session,
    )
